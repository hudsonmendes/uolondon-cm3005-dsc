{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework Assignment: Building a Regression Model\n",
    "\n",
    "```\n",
    "University of London\n",
    "BSc in Computer Science\n",
    "CM3005, Data Science\n",
    "Hudson Leonardo MENDES\n",
    "hlm12@student.london.ac.uk\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-specific area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_folderpath = pathlib.Path(\"./data\")\n",
    "\n",
    "ppd_folderpath = data_folderpath / \"uk-ppd\"\n",
    "inflation_filepath = data_folderpath / \"uk-ons/ons-inflation-1989-2022.csv\"\n",
    "interest_filepath = data_folderpath / \"uk-boe/boe-interest-1975-2022.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gov.uk/guidance/about-the-price-paid-data\n",
    "ppd_property_type = {\n",
    "    \"D\": \"detached\",\n",
    "    \"S\": \"semi-detached\",\n",
    "    \"T\": \"terraced\",\n",
    "    \"F\": \"flat/maisonettes\",\n",
    "    # \"O\": \"other\" # => intentionally ommitted\n",
    "}\n",
    "\n",
    "ppd_duration = {\"F\": \"freehold\", \"L\": \"leasehold\"}\n",
    "\n",
    "ppd_old_or_new = {\"Y\": \"new\", \"N\": \"old\"}\n",
    "\n",
    "ppd_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\n",
    "            ppd_filepath,\n",
    "            compression=\"zip\",\n",
    "            names=[\n",
    "                \"id\",\n",
    "                \"price\",\n",
    "                \"date\",\n",
    "                \"postcode\",\n",
    "                \"property_type\",\n",
    "                \"old_or_new\",\n",
    "                \"duration\",\n",
    "                \"paon\",\n",
    "                \"saon\",\n",
    "                \"street\",\n",
    "                \"locality\",\n",
    "                \"town_city\",\n",
    "                \"district\",\n",
    "                \"county\",\n",
    "                \"ppd_category_type\",\n",
    "                \"record_status\",\n",
    "            ],\n",
    "        )\n",
    "        for ppd_filepath in ppd_folderpath.glob(\"*.zip\")\n",
    "    ]\n",
    ")\n",
    "ppd_df[\"postgroup\"] = ppd_df[\"postcode\"].map(lambda x: str(x).split(\" \")[0])\n",
    "ppd_df[\"date\"] = pd.to_datetime(ppd_df[\"date\"])\n",
    "ppd_df[\"property_type\"] = ppd_df[\"property_type\"].map(ppd_property_type.get)\n",
    "ppd_df[\"duration\"] = ppd_df[\"duration\"].map(ppd_duration.get)\n",
    "ppd_df[\"old_or_new\"] = ppd_df[\"old_or_new\"].map(ppd_old_or_new.get)\n",
    "ppd_df = ppd_df[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"postgroup\",\n",
    "        \"property_type\",\n",
    "        \"old_or_new\",\n",
    "        \"duration\",\n",
    "        \"price\",\n",
    "    ]\n",
    "]\n",
    "ppd_df = ppd_df.astype(\n",
    "    {\n",
    "        \"postgroup\": \"category\",\n",
    "        \"property_type\": \"category\",\n",
    "        \"old_or_new\": \"category\",\n",
    "        \"duration\": \"category\",\n",
    "        \"price\": \"double\",\n",
    "    }\n",
    ")\n",
    "ppd_df = ppd_df.dropna()\n",
    "ppd_df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from datetime import date\n",
    "\n",
    "inflation_date_pattern = re.compile(r\"([\\d]{4})(?:\\s+([\\w]{3}))?\")\n",
    "inflation_month_names = [\n",
    "    \"JAN\",\n",
    "    \"FEB\",\n",
    "    \"MAR\",\n",
    "    \"APR\",\n",
    "    \"MAY\",\n",
    "    \"JUN\",\n",
    "    \"JUL\",\n",
    "    \"AUG\",\n",
    "    \"SEP\",\n",
    "    \"OCT\",\n",
    "    \"NOV\",\n",
    "    \"DEC\",\n",
    "]\n",
    "inflation_month_index = {mn: ix + 1 for (ix, mn) in enumerate(inflation_month_names)}\n",
    "inflation_month_index[\"Q1\"] = 1\n",
    "inflation_month_index[\"Q2\"] = 4\n",
    "inflation_month_index[\"Q3\"] = 7\n",
    "inflation_month_index[\"Q3\"] = 10\n",
    "\n",
    "inflation_acceptable_numeric_chars = string.digits + \".,\"\n",
    "\n",
    "\n",
    "def extract_inflation_date(x: str) -> date:\n",
    "    match = next(inflation_date_pattern.finditer(x), None)\n",
    "    if match:\n",
    "        group_count = len(match.groups())\n",
    "        if group_count >= 1:\n",
    "            year = int(match.group(1))\n",
    "            month = 1\n",
    "            month_name = match.group(2)\n",
    "            if group_count > 1 and month_name:\n",
    "                month_name = month_name.strip().upper()\n",
    "                month = inflation_month_index.get(month_name)\n",
    "            return date(year, month, 1)\n",
    "\n",
    "\n",
    "def extract_inflation_rate(x: str) -> float:\n",
    "    x = str(x)\n",
    "    if all([c in inflation_acceptable_numeric_chars for c in x]):\n",
    "        return float(x)\n",
    "    return None\n",
    "\n",
    "\n",
    "inflation_df = pd.read_csv(inflation_filepath)\n",
    "inflation_df[\"date\"] = inflation_df[\"Title\"].map(extract_inflation_date)\n",
    "inflation_df[\"date\"] = pd.to_datetime(inflation_df[\"date\"])\n",
    "inflation_df[\"rate\"] = inflation_df[\"CPIH ANNUAL RATE 00: ALL ITEMS 2015=100\"].map(\n",
    "    extract_inflation_rate\n",
    ")\n",
    "inflation_df[\"rate\"] = inflation_df[\"rate\"].astype(\"float\", errors=\"ignore\")\n",
    "inflation_df = inflation_df[[\"date\", \"rate\"]]\n",
    "inflation_df = inflation_df.dropna()\n",
    "inflation_df = inflation_df.set_index(\"date\").sort_index()\n",
    "inflation_df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_df = pd.read_csv(interest_filepath)\n",
    "interest_df[\"date\"] = pd.to_datetime(interest_df[\"Date Changed\"])\n",
    "interest_df[\"rate\"] = interest_df[\"Rate\"].astype(\"float\")\n",
    "interest_df = interest_df[[\"date\", \"rate\"]]\n",
    "interest_df = interest_df.set_index(\"date\").sort_index()\n",
    "interest_df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from typing import Callable\n",
    "from datetime import date, timedelta\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def build_rate_extractor(df: pd.DataFrame) -> Callable[[date], float]:\n",
    "    min_date = df.index.min()\n",
    "    max_date = df.index.max()\n",
    "    cur_date = min_date\n",
    "    rate_index = {}\n",
    "    first_rate = df.rate[0]\n",
    "    prev_rate = first_rate\n",
    "    last_rate = df.rate[-1]\n",
    "    with trange((max_date - min_date).days, desc=\"rate_index\") as pbar:\n",
    "        while cur_date <= max_date:\n",
    "            rates = df[df.index == cur_date].rate\n",
    "            if rates.any():\n",
    "                new_rate = rates[0] / 100.0\n",
    "                rate_index[cur_date] = new_rate\n",
    "                prev_rate = new_rate\n",
    "            else:\n",
    "                rate_index[cur_date] = prev_rate\n",
    "            cur_date += timedelta(days=1)\n",
    "            pbar.update()\n",
    "\n",
    "    def get_rate_for_date(d: date) -> float:\n",
    "        if d < min_date:\n",
    "            return first_rate\n",
    "        elif d > max_date:\n",
    "            return last_rate\n",
    "        else:\n",
    "            return rate_index[d]\n",
    "\n",
    "    return get_rate_for_date\n",
    "\n",
    "\n",
    "df = ppd_df.copy()\n",
    "df[\"inflation_rate\"] = df.date.progress_map(build_rate_extractor(df=inflation_df))\n",
    "df[\"interest_rate\"] = df.date.progress_map(build_rate_extractor(df=interest_df))\n",
    "df[\"date_year\"] = df.date.progress_map(lambda d: d.year)\n",
    "df[\"date_month\"] = df.date.progress_map(lambda d: d.month)\n",
    "df[\"date_day\"] = df.date.progress_map(lambda d: d.day)\n",
    "df[\"date_day_of_week\"] = df.date.progress_map(lambda d: d.weekday())\n",
    "df = df.sort_values(by=\"date\").reset_index()\n",
    "df = df[\n",
    "    [\"date_year\", \"date_month\", \"date_day\", \"date_day_of_week\"]\n",
    "    + list(ppd_df.columns[1:-1])\n",
    "    + [\"inflation_rate\", \"interest_rate\", \"price\"]\n",
    "]\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_folderpath / \"snapshot-Xy-1NF.zip\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert df is not None\n",
    "except NameError:\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"[SNAPSHOT] Reloading...\")\n",
    "    pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n",
    "    data_folderpath = pathlib.Path(\"./data\")\n",
    "    df = pd.read_csv(data_folderpath / \"snapshot-Xy-1NF.zip\").astype(\n",
    "        {\n",
    "            \"postgroup\": \"category\",\n",
    "            \"property_type\": \"category\",\n",
    "            \"old_or_new\": \"category\",\n",
    "            \"duration\": \"category\",\n",
    "            \"price\": \"double\",\n",
    "        }\n",
    "    )\n",
    "    print(f\" - reloaded from snapshot, {df.shape[0]}\")\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Central Tendency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Measures of Spread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Type of distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert df is not None\n",
    "except NameError:\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "\n",
    "    print(\"[SNAPSHOT] Reloading...\")\n",
    "    pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n",
    "    data_folderpath = pathlib.Path(\"./data\")\n",
    "    df = pd.read_csv(data_folderpath / \"snapshot-Xy-1NF.zip\").astype(\n",
    "        {\n",
    "            \"postgroup\": \"category\",\n",
    "            \"property_type\": \"category\",\n",
    "            \"old_or_new\": \"category\",\n",
    "            \"duration\": \"category\",\n",
    "            \"price\": \"double\",\n",
    "        }\n",
    "    )\n",
    "    print(f\" - reloaded from snapshot, {df.shape[0]}\")\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "max_price = float(df.price.max())\n",
    "max_rate = max(df.interest_rate.max(), df.inflation_rate.max())\n",
    "min_intersecting_date = date(df.date_year.min(), 1, 1)\n",
    "max_intersecting_date = date(df.date_year.max(), 12, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(ncols=2, nrows=1, figsize=(15, 5))\n",
    "\n",
    "\n",
    "def plot_rate_distributions(ax, df: pd.DataFrame, label: str, color: str):\n",
    "    df = df.copy()\n",
    "    x = np.linspace(0.0, df[\"rate\"].max(), 100)\n",
    "    df[\"bin\"] = pd.cut(df[\"rate\"], bins=x)\n",
    "    y = list(df.groupby(\"bin\").count()[\"rate\"])\n",
    "    ax.fill_between(x[:-1], 0.0, y, color=color, alpha=0.5)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter(\"%2.2f%%\"))\n",
    "    intervals = [0.05, 0.95]\n",
    "    for interval, quantile in zip(intervals, df.rate.quantile(intervals)):\n",
    "        percentile = f\"P{int(interval*100.)}={round(quantile, 2)}\"\n",
    "        bbox = dict(boxstyle=\"round, pad=0.3\", fc=\"lightgray\", lw=2)\n",
    "        ax.axvline(x=quantile, color=\"blue\")\n",
    "        ax.annotate(\n",
    "            percentile,\n",
    "            xy=(quantile, max(y)),\n",
    "            bbox=bbox,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    ax.axvline(x=quantile, color=\"blue\")\n",
    "    ax.legend([label], loc=\"lower center\", bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "\n",
    "plot_rate_distributions(\n",
    "    ax=axes[0],\n",
    "    df=interest_df,\n",
    "    label=\"interest\",\n",
    "    color=\"green\",\n",
    ")\n",
    "\n",
    "plot_rate_distributions(\n",
    "    ax=axes[1],\n",
    "    df=inflation_df,\n",
    "    label=\"inflation\",\n",
    "    color=\"red\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "\n",
    "_, axes = plt.subplots(nrows=2, figsize=(15, 10), sharex=True)\n",
    "\n",
    "series = df.copy()\n",
    "series[\"date\"] = df.apply(lambda r: date(r.date_year, r.date_month, r.date_day), axis=1)\n",
    "series = series.groupby(\"date\").mean(numeric_only=True).dropna()\n",
    "\n",
    "x = series.index\n",
    "\n",
    "axes[0].grid(visible=True)\n",
    "axes[0].plot(x, series.interest_rate * 100.0, \"g.-\", alpha=0.7)\n",
    "axes[0].plot(x, series.inflation_rate * 100.0, \"r.-\", alpha=0.7)\n",
    "axes[0].set_xlim(left=min_intersecting_date, right=max_intersecting_date)\n",
    "axes[0].set_ylabel(\"rates (%)\")\n",
    "axes[0].yaxis.set_major_formatter(FormatStrFormatter(\"%2.2f%%\"))\n",
    "axes[0].legend([\"interest\", \"inflation\"])\n",
    "\n",
    "axes[1].grid(visible=True)\n",
    "axes[1].yaxis.set_major_formatter(StrMethodFormatter(\"{x:,}\"))\n",
    "axes[1].set_ylim(0.0, df.price.quantile(0.95) * 1.2)\n",
    "axes[1].set_ylabel(\"property price (£)\")\n",
    "for ix, property_type in tqdm(list(enumerate(ppd_property_type.values()))):\n",
    "    sub_series = df[df.property_type == property_type].copy()\n",
    "    sub_series[\"date_ym\"] = sub_series.apply(\n",
    "        lambda r: date(r.date_year, r.date_month, 1), axis=1\n",
    "    )\n",
    "    sub_series = sub_series[[\"date_ym\", \"price\"]]\n",
    "    sub_series = sub_series.groupby(\"date_ym\").mean(numeric_only=True)\n",
    "    sub_series = sub_series.fillna(method=\"ffill\")\n",
    "    axes[1].plot(sub_series.index, sub_series.price, \"s\", alpha=0.7)\n",
    "    axes[1].legend(ppd_property_type.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:29:35.381071Z",
     "start_time": "2022-12-26T20:29:28.983657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SNAPSHOT] Reloading...\n",
      " - reloaded from snapshot, 4336841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_day_of_week</th>\n",
       "      <th>postgroup</th>\n",
       "      <th>property_type</th>\n",
       "      <th>old_or_new</th>\n",
       "      <th>duration</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>778875</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>DY2</td>\n",
       "      <td>flat/maisonettes</td>\n",
       "      <td>new</td>\n",
       "      <td>leasehold</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.007</td>\n",
       "      <td>89,950.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223940</th>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>BD20</td>\n",
       "      <td>terraced</td>\n",
       "      <td>old</td>\n",
       "      <td>freehold</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.013</td>\n",
       "      <td>197,500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857487</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>RG41</td>\n",
       "      <td>semi-detached</td>\n",
       "      <td>old</td>\n",
       "      <td>freehold</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>650,000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694807</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>DA11</td>\n",
       "      <td>terraced</td>\n",
       "      <td>new</td>\n",
       "      <td>freehold</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.007</td>\n",
       "      <td>380,000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093028</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>CR2</td>\n",
       "      <td>flat/maisonettes</td>\n",
       "      <td>old</td>\n",
       "      <td>leasehold</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.001</td>\n",
       "      <td>216,000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_year  date_month  date_day  date_day_of_week postgroup  \\\n",
       "778875        2018          10        29                 0       DY2   \n",
       "4223940       2022           7        29                 4      BD20   \n",
       "2857487       2021           2        18                 3      RG41   \n",
       "694807        2018           9        28                 4      DA11   \n",
       "3093028       2021           4        22                 3       CR2   \n",
       "\n",
       "            property_type old_or_new   duration  inflation_rate  \\\n",
       "778875   flat/maisonettes        new  leasehold           0.022   \n",
       "4223940          terraced        old   freehold           0.088   \n",
       "2857487     semi-detached        old   freehold           0.007   \n",
       "694807           terraced        new   freehold           0.022   \n",
       "3093028  flat/maisonettes        old  leasehold           0.016   \n",
       "\n",
       "         interest_rate       price  \n",
       "778875           0.007  89,950.000  \n",
       "4223940          0.013 197,500.000  \n",
       "2857487          0.001 650,000.000  \n",
       "694807           0.007 380,000.000  \n",
       "3093028          0.001 216,000.000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    assert df is not None\n",
    "except NameError:\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"[SNAPSHOT] Reloading...\")\n",
    "    pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n",
    "    data_folderpath = pathlib.Path(\"./data\")\n",
    "    df = pd.read_csv(data_folderpath / \"snapshot-Xy-1NF.zip\").astype(\n",
    "        {\n",
    "            \"postgroup\": \"category\",\n",
    "            \"property_type\": \"category\",\n",
    "            \"old_or_new\": \"category\",\n",
    "            \"duration\": \"category\",\n",
    "            \"price\": \"double\",\n",
    "        }\n",
    "    )\n",
    "    print(f\" - reloaded from snapshot, {df.shape[0]}\")\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:29:35.546838Z",
     "start_time": "2022-12-26T20:29:35.387396Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = df[df.columns[:-1]], df[df.columns[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:29:46.807446Z",
     "start_time": "2022-12-26T20:29:35.553781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] . (1 of 6) Processing onehotencoder, total=   4.2s\n",
      "[ColumnTransformer]  (2 of 6) Processing standardscaler-1, total=   0.1s\n",
      "[ColumnTransformer]  (3 of 6) Processing standardscaler-2, total=   0.1s\n",
      "[ColumnTransformer]  (4 of 6) Processing functiontransformer-1, total=   0.1s\n",
      "[ColumnTransformer]  (5 of 6) Processing functiontransformer-2, total=   0.1s\n",
      "[ColumnTransformer]  (6 of 6) Processing functiontransformer-3, total=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2306</th>\n",
       "      <th>2307</th>\n",
       "      <th>2308</th>\n",
       "      <th>2309</th>\n",
       "      <th>2310</th>\n",
       "      <th>2311</th>\n",
       "      <th>2312</th>\n",
       "      <th>2313</th>\n",
       "      <th>2314</th>\n",
       "      <th>2315</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336836</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.504</td>\n",
       "      <td>4.581</td>\n",
       "      <td>1.617</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336837</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.504</td>\n",
       "      <td>4.581</td>\n",
       "      <td>1.617</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336838</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.504</td>\n",
       "      <td>4.581</td>\n",
       "      <td>1.617</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336839</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.504</td>\n",
       "      <td>4.581</td>\n",
       "      <td>1.617</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336840</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.504</td>\n",
       "      <td>4.581</td>\n",
       "      <td>1.617</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336841 rows × 2316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "0       0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "1       0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "2       0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "3       0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "4       0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "4336836 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "4336837 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "4336838 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "4336839 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "4336840 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  ...   \n",
       "\n",
       "         2306  2307  2308  2309  2310  2311   2312   2313   2314   2315  \n",
       "0       0.000 1.000 1.000 0.000 0.089 0.039 -1.361  0.500  0.201  0.000  \n",
       "1       0.000 1.000 1.000 0.000 0.089 0.039 -1.361  0.500  0.201  0.000  \n",
       "2       0.000 1.000 0.000 1.000 0.089 0.039 -1.361  0.500  0.201  0.000  \n",
       "3       0.000 1.000 1.000 0.000 0.089 0.039 -1.361  0.500  0.201  0.000  \n",
       "4       0.000 1.000 1.000 0.000 0.089 0.039 -1.361  0.500  0.201  0.000  \n",
       "...       ...   ...   ...   ...   ...   ...    ...    ...    ...    ...  \n",
       "4336836 0.000 1.000 0.000 1.000 3.504 4.581  1.617 -0.866 -0.938  0.866  \n",
       "4336837 0.000 1.000 1.000 0.000 3.504 4.581  1.617 -0.866 -0.849  0.866  \n",
       "4336838 0.000 1.000 1.000 0.000 3.504 4.581  1.617 -0.866 -0.849  0.866  \n",
       "4336839 0.000 1.000 1.000 0.000 3.504 4.581  1.617 -0.866 -0.571 -0.866  \n",
       "4336840 0.000 1.000 1.000 0.000 3.504 4.581  1.617 -0.866 -0.394 -0.866  \n",
       "\n",
       "[4336841 rows x 2316 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "\n",
    "def make_sine_cycle_encoder(period: int = 1) -> float:\n",
    "    assert period != 0\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use\n",
    "def make_df_column_transformer():\n",
    "    categorical_selector = make_column_selector(dtype_include=\"category\")\n",
    "    float_seletor = make_column_selector(dtype_include=\"float64\")\n",
    "    one_hot = OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\")\n",
    "    numerical_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    cycle_sine_12 = make_sine_cycle_encoder(period=12)\n",
    "    cycle_sine_31 = make_sine_cycle_encoder(period=31)\n",
    "    cycle_sine_6 = make_sine_cycle_encoder(period=6)\n",
    "    return make_column_transformer(\n",
    "        (one_hot, categorical_selector),\n",
    "        (numerical_scaler, float_seletor),\n",
    "        (numerical_scaler, [\"date_year\"]),\n",
    "        (cycle_sine_12, [\"date_month\"]),\n",
    "        (cycle_sine_31, [\"date_day\"]),\n",
    "        (cycle_sine_6, [\"date_day_of_week\"]),\n",
    "        remainder=\"drop\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "preprocessing_df_column_transformer = make_df_column_transformer()\n",
    "X_encoded = preprocessing_df_column_transformer.fit_transform(X)\n",
    "pd.DataFrame.sparse.from_spmatrix(X_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:29:49.528336Z",
     "start_time": "2022-12-26T20:29:46.838996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>|X|</th>\n",
       "      <th>|y|</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>4336841</td>\n",
       "      <td>4336841</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>4293472</td>\n",
       "      <td>4293472</td>\n",
       "      <td>99.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>43369</td>\n",
       "      <td>43369</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split      |X|      |y|       %\n",
       "0   full  4336841  4336841  100.0%\n",
       "1  train  4293472  4293472   99.0%\n",
       "2   test    43369    43369    1.0%"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def produce_split_summary(\n",
    "    X_split: pd.DataFrame, y_split: pd.DataFrame, name: str, total: int\n",
    ") -> Tuple[str, int, int, str]:\n",
    "    return (\n",
    "        name,\n",
    "        X_split.shape[0],\n",
    "        y_split.shape[0],\n",
    "        \"{:.1f}%\".format(100.0 * X_split.shape[0] / total),\n",
    "    )\n",
    "\n",
    "\n",
    "r = 42\n",
    "train_size = 0.99\n",
    "X1, X2, y1, y2 = train_test_split(X_encoded, y, train_size=train_size, random_state=r)\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        produce_split_summary(X, y, \"full\", total=X.shape[0]),\n",
    "        produce_split_summary(X1, y1, \"train\", total=X.shape[0]),\n",
    "        produce_split_summary(X2, y2, \"test\", total=X.shape[0]),\n",
    "    ],\n",
    "    columns=[\"split\", \"|X|\", \"|y|\", \"%\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:30:07.856184Z",
     "start_time": "2022-12-26T20:29:49.535386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 129946195645.34506226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spit</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>-0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>-0.502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spit  score\n",
       "0  train -0.624\n",
       "1   test -0.502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "def make_model(hidden_layer_sizes: Tuple[int, ...], max_iter: int):\n",
    "    r = 42\n",
    "    return MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        validation_fraction=0.01,\n",
    "        random_state=r,\n",
    "        verbose=True,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "\n",
    "\n",
    "model = make_model(hidden_layer_sizes=(2,), max_iter=1)\n",
    "model.fit(X1, y1)\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        (\"train\", model.score(X1, y1)),\n",
    "        (\"test\", model.score(X2, y2)),\n",
    "    ],\n",
    "    columns=[\"spit\", \"score\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:30:07.914517Z",
     "start_time": "2022-12-26T20:30:07.862556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=MLPRegressor(hidden_layer_sizes=(2,), max_iter=1,\n",
       "                                    random_state=42, validation_fraction=0.01,\n",
       "                                    verbose=True),\n",
       "             param_grid={&#x27;hidden_layer_sizes&#x27;: [(2, 4), (3, 4), (4, 4), (8, 4),\n",
       "                                                (16, 4)],\n",
       "                         &#x27;max_iter&#x27;: [10]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=MLPRegressor(hidden_layer_sizes=(2,), max_iter=1,\n",
       "                                    random_state=42, validation_fraction=0.01,\n",
       "                                    verbose=True),\n",
       "             param_grid={&#x27;hidden_layer_sizes&#x27;: [(2, 4), (3, 4), (4, 4), (8, 4),\n",
       "                                                (16, 4)],\n",
       "                         &#x27;max_iter&#x27;: [10]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(2,), max_iter=1, random_state=42,\n",
       "             validation_fraction=0.01, verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(2,), max_iter=1, random_state=42,\n",
       "             validation_fraction=0.01, verbose=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPRegressor(hidden_layer_sizes=(2,), max_iter=1,\n",
       "                                    random_state=42, validation_fraction=0.01,\n",
       "                                    verbose=True),\n",
       "             param_grid={'hidden_layer_sizes': [(2, 4), (3, 4), (4, 4), (8, 4),\n",
       "                                                (16, 4)],\n",
       "                         'max_iter': [10]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Set, List, Tuple\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (2, 4),\n",
    "            (3, 4),\n",
    "            (4, 4),\n",
    "            (8, 4),\n",
    "            (16, 4),\n",
    "        ],\n",
    "        \"max_iter\": [10],\n",
    "    },\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    ")\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T22:47:59.399922Z",
     "start_time": "2022-12-26T20:30:07.938204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Iteration 1, loss = 116537180839.55850220\n",
      "Iteration 2, loss = 80761463472.32351685\n",
      "Iteration 3, loss = 70791052660.83818054\n",
      "Iteration 4, loss = 68091691832.29521942\n",
      "Iteration 5, loss = 66269109792.86598206\n",
      "Iteration 6, loss = 64521804256.27986908\n",
      "Iteration 7, loss = 62535351791.22803497\n",
      "Iteration 8, loss = 60415182141.98910522\n",
      "Iteration 9, loss = 58493688581.13388062\n",
      "Iteration 10, loss = 57002419489.90628815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END hidden_layer_sizes=(2, 4), max_iter=10;, score=0.171 total time= 4.1min\n",
      "Iteration 1, loss = 125005543486.08050537\n",
      "Iteration 2, loss = 89233705548.53434753\n",
      "Iteration 3, loss = 79265643326.22076416\n",
      "Iteration 4, loss = 76582553050.11213684\n",
      "Iteration 5, loss = 74767481606.29716492\n",
      "Iteration 6, loss = 73028843746.78851318\n",
      "Iteration 7, loss = 71136353179.88880920\n",
      "Iteration 8, loss = 69085334782.11497498\n",
      "Iteration 9, loss = 67161275285.62870026\n",
      "Iteration 10, loss = 65657288485.71463013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END hidden_layer_sizes=(2, 4), max_iter=10;, score=0.252 total time= 4.2min\n",
      "Iteration 1, loss = 120518233842.34460449\n",
      "Iteration 2, loss = 83376781659.88890076\n",
      "Iteration 3, loss = 76663916746.66841125\n",
      "Iteration 4, loss = 74120578816.20677185\n",
      "Iteration 5, loss = 72175283635.11212158\n",
      "Iteration 6, loss = 70046028560.13327026\n",
      "Iteration 7, loss = 67725309326.87785339\n",
      "Iteration 8, loss = 65537748301.86626434\n",
      "Iteration 9, loss = 63890187196.48462677\n",
      "Iteration 10, loss = 62687024557.79617310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END hidden_layer_sizes=(2, 4), max_iter=10;, score=0.248 total time= 3.7min\n",
      "Iteration 1, loss = 121972747380.89706421\n",
      "Iteration 2, loss = 86170308864.48503113\n",
      "Iteration 3, loss = 76223503924.85212708\n",
      "Iteration 4, loss = 73523211081.89280701\n",
      "Iteration 5, loss = 71695915565.73443604\n",
      "Iteration 6, loss = 69967450919.52796936\n",
      "Iteration 7, loss = 68047239680.02334595\n",
      "Iteration 8, loss = 65983079531.76647949\n",
      "Iteration 9, loss = 64080494327.50776672\n",
      "Iteration 10, loss = 62542308862.95951080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END hidden_layer_sizes=(2, 4), max_iter=10;, score=0.215 total time= 4.0min\n",
      "Iteration 1, loss = 124658197079.83718872\n",
      "Iteration 2, loss = 88868809941.84579468\n",
      "Iteration 3, loss = 78885075741.59284973\n",
      "Iteration 4, loss = 76195958127.33645630\n",
      "Iteration 5, loss = 74364762196.95271301\n",
      "Iteration 6, loss = 72631171237.25038147\n",
      "Iteration 7, loss = 70718272277.78771973\n",
      "Iteration 8, loss = 68662827436.80850983\n",
      "Iteration 9, loss = 66759917275.97394562\n",
      "Iteration 10, loss = 65211745557.88530731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END hidden_layer_sizes=(2, 4), max_iter=10;, score=0.244 total time= 4.8min\n",
      "Iteration 1, loss = 124463702206.09841919\n",
      "Iteration 2, loss = 124458260175.30221558\n",
      "Iteration 3, loss = 124452821123.57171631\n",
      "Iteration 4, loss = 124447377793.32217407\n",
      "Iteration 5, loss = 124441939211.02917480\n",
      "Iteration 6, loss = 124436495851.37773132\n",
      "Iteration 7, loss = 124431057705.27668762\n",
      "Iteration 8, loss = 124425617383.04949951\n",
      "Iteration 9, loss = 124420179124.62178040\n",
      "Iteration 10, loss = 124414742724.58718872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END hidden_layer_sizes=(3, 4), max_iter=10;, score=-0.493 total time= 5.2min\n",
      "Iteration 1, loss = 132920870249.06993103\n",
      "Iteration 2, loss = 132915428098.22882080\n",
      "Iteration 3, loss = 132909989261.43649292\n",
      "Iteration 4, loss = 132904550487.79533386\n",
      "Iteration 5, loss = 132899110552.75694275\n",
      "Iteration 6, loss = 132893669312.91693115\n",
      "Iteration 7, loss = 132888230449.66456604\n",
      "Iteration 8, loss = 132882791436.22843933\n",
      "Iteration 9, loss = 132877352864.45970154\n",
      "Iteration 10, loss = 132871917713.52175903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END hidden_layer_sizes=(3, 4), max_iter=10;, score=-0.732 total time= 5.3min\n",
      "Iteration 1, loss = 131461621485.24711609\n",
      "Iteration 2, loss = 131456176127.81387329\n",
      "Iteration 3, loss = 131450735396.56501770\n",
      "Iteration 4, loss = 131445290564.91346741\n",
      "Iteration 5, loss = 131439854090.45745850\n",
      "Iteration 6, loss = 131434411807.97700500\n",
      "Iteration 7, loss = 131428972488.05035400\n",
      "Iteration 8, loss = 131423533402.34310913\n",
      "Iteration 9, loss = 131418094476.56262207\n",
      "Iteration 10, loss = 131412654656.59336853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END hidden_layer_sizes=(3, 4), max_iter=10;, score=-0.674 total time= 5.0min\n",
      "Iteration 1, loss = 129888405818.29980469\n",
      "Iteration 2, loss = 129882962545.93354797\n",
      "Iteration 3, loss = 129877518492.77578735\n",
      "Iteration 4, loss = 129872079210.16864014\n",
      "Iteration 5, loss = 129866640789.00119019\n",
      "Iteration 6, loss = 129861195104.50701904\n",
      "Iteration 7, loss = 129855757576.08647156\n",
      "Iteration 8, loss = 129850318843.74612427\n",
      "Iteration 9, loss = 129844879998.44837952\n",
      "Iteration 10, loss = 129839439976.73170471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END hidden_layer_sizes=(3, 4), max_iter=10;, score=-0.622 total time= 5.0min\n",
      "Iteration 1, loss = 132575864441.62911987\n",
      "Iteration 2, loss = 132570422561.27354431\n",
      "Iteration 3, loss = 132564979209.41978455\n",
      "Iteration 4, loss = 132559538787.72904968\n",
      "Iteration 5, loss = 132554099352.30273438\n",
      "Iteration 6, loss = 132548652667.76820374\n",
      "Iteration 7, loss = 132543216649.36468506\n",
      "Iteration 8, loss = 132537778915.17199707\n",
      "Iteration 9, loss = 132532338027.40228271\n",
      "Iteration 10, loss = 132526898129.63342285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END hidden_layer_sizes=(3, 4), max_iter=10;, score=-0.716 total time= 4.6min\n",
      "Iteration 1, loss = 110743642704.62802124\n",
      "Iteration 2, loss = 74116297715.65849304\n",
      "Iteration 3, loss = 68906782502.18496704\n",
      "Iteration 4, loss = 66421603532.18337250\n",
      "Iteration 5, loss = 64238656834.79212952\n",
      "Iteration 6, loss = 61720864806.35443115\n",
      "Iteration 7, loss = 59139491973.70907593\n",
      "Iteration 8, loss = 57131849110.26185608\n",
      "Iteration 9, loss = 55761450853.98509979\n",
      "Iteration 10, loss = 54757222337.98211670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END hidden_layer_sizes=(4, 4), max_iter=10;, score=0.191 total time= 5.1min\n",
      "Iteration 1, loss = 119219700329.54650879\n",
      "Iteration 2, loss = 82579010413.31042480\n",
      "Iteration 3, loss = 77379751218.52574158\n",
      "Iteration 4, loss = 74911791685.62098694\n",
      "Iteration 5, loss = 72747308650.82095337\n",
      "Iteration 6, loss = 70331298168.88389587\n",
      "Iteration 7, loss = 67779537798.90168762\n",
      "Iteration 8, loss = 65741905034.10162354\n",
      "Iteration 9, loss = 64349626688.91780090\n",
      "Iteration 10, loss = 63338445415.79711151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END hidden_layer_sizes=(4, 4), max_iter=10;, score=0.283 total time= 4.6min\n",
      "Iteration 1, loss = 117765424383.18458557\n",
      "Iteration 2, loss = 81135448235.96640015\n",
      "Iteration 3, loss = 75870469067.11126709\n",
      "Iteration 4, loss = 73418336134.59747314\n",
      "Iteration 5, loss = 71260107433.36206055\n",
      "Iteration 6, loss = 68794383911.71038818\n",
      "Iteration 7, loss = 66257382505.33696747\n",
      "Iteration 8, loss = 64242961603.10024261\n",
      "Iteration 9, loss = 62847969752.24678802\n",
      "Iteration 10, loss = 61829158460.25091553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END hidden_layer_sizes=(4, 4), max_iter=10;, score=0.259 total time= 4.8min\n",
      "Iteration 1, loss = 116185750374.59788513\n",
      "Iteration 2, loss = 79555080967.76846313\n",
      "Iteration 3, loss = 74286987746.56005859\n",
      "Iteration 4, loss = 71841681673.44865417\n",
      "Iteration 5, loss = 69667529441.50236511\n",
      "Iteration 6, loss = 67172679645.66815948\n",
      "Iteration 7, loss = 64628744456.39997864\n",
      "Iteration 8, loss = 62624266829.08331299\n",
      "Iteration 9, loss = 61236484160.47196198\n",
      "Iteration 10, loss = 60235633926.56857300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END hidden_layer_sizes=(4, 4), max_iter=10;, score=0.241 total time= 4.9min\n",
      "Iteration 1, loss = 118864895656.46527100\n",
      "Iteration 2, loss = 82219946906.96893311\n",
      "Iteration 3, loss = 76975572883.48075867\n",
      "Iteration 4, loss = 74521417883.04370117\n",
      "Iteration 5, loss = 72357166550.47789001\n",
      "Iteration 6, loss = 69889677547.77111816\n",
      "Iteration 7, loss = 67359273445.29254913\n",
      "Iteration 8, loss = 65330705022.95080566\n",
      "Iteration 9, loss = 63911413360.50464630\n",
      "Iteration 10, loss = 62888322653.67573547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END hidden_layer_sizes=(4, 4), max_iter=10;, score=0.273 total time= 5.1min\n",
      "Iteration 1, loss = 96189702225.78398132\n",
      "Iteration 2, loss = 69034532208.59458923\n",
      "Iteration 3, loss = 65058952828.18436432\n",
      "Iteration 4, loss = 61055974707.79560089\n",
      "Iteration 5, loss = 57357424741.07167053\n",
      "Iteration 6, loss = 55052209851.67828369\n",
      "Iteration 7, loss = 53534305860.08687592\n",
      "Iteration 8, loss = 52267192574.14588928\n",
      "Iteration 9, loss = 51149396203.24585724\n",
      "Iteration 10, loss = 50160304454.67521667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END hidden_layer_sizes=(8, 4), max_iter=10;, score=0.237 total time= 3.4min\n",
      "Iteration 1, loss = 104617073648.94381714\n",
      "Iteration 2, loss = 77487864771.79450989\n",
      "Iteration 3, loss = 73556226953.38354492\n",
      "Iteration 4, loss = 69720127521.24243164\n",
      "Iteration 5, loss = 66054266501.49440765\n",
      "Iteration 6, loss = 63696020792.25295258\n",
      "Iteration 7, loss = 62146981798.38996124\n",
      "Iteration 8, loss = 60881593270.62611389\n",
      "Iteration 9, loss = 59764231692.39842224\n",
      "Iteration 10, loss = 58778091184.04358673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END hidden_layer_sizes=(8, 4), max_iter=10;, score=0.349 total time= 3.6min\n",
      "Iteration 1, loss = 103895534665.36614990\n",
      "Iteration 2, loss = 76030783767.17703247\n",
      "Iteration 3, loss = 71988977990.36811829\n",
      "Iteration 4, loss = 68039050762.74380493\n",
      "Iteration 5, loss = 64364698936.86511993\n",
      "Iteration 6, loss = 62004226320.94968414\n",
      "Iteration 7, loss = 60439025235.57301331\n",
      "Iteration 8, loss = 59201159267.25621796\n",
      "Iteration 9, loss = 58139612814.93318176\n",
      "Iteration 10, loss = 57198054618.85047913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END hidden_layer_sizes=(8, 4), max_iter=10;, score=0.320 total time= 3.8min\n",
      "Iteration 1, loss = 101935453352.57774353\n",
      "Iteration 2, loss = 74444987528.47241211\n",
      "Iteration 3, loss = 70434401875.80992126\n",
      "Iteration 4, loss = 66528563391.86125183\n",
      "Iteration 5, loss = 62870082105.30548096\n",
      "Iteration 6, loss = 60524194518.77929688\n",
      "Iteration 7, loss = 58986221730.28992462\n",
      "Iteration 8, loss = 57723366386.48702240\n",
      "Iteration 9, loss = 56628420912.54097748\n",
      "Iteration 10, loss = 55639630930.73387909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END hidden_layer_sizes=(8, 4), max_iter=10;, score=0.300 total time= 3.2min\n",
      "Iteration 1, loss = 104964365183.41217041\n",
      "Iteration 2, loss = 77137442374.20715332\n",
      "Iteration 3, loss = 73077286975.47445679\n",
      "Iteration 4, loss = 69157497630.60223389\n",
      "Iteration 5, loss = 65488236800.45494843\n",
      "Iteration 6, loss = 63131929385.33524323\n",
      "Iteration 7, loss = 61580699579.54413605\n",
      "Iteration 8, loss = 60318421145.94735718\n",
      "Iteration 9, loss = 59235037742.27500153\n",
      "Iteration 10, loss = 58255579258.02764130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END hidden_layer_sizes=(8, 4), max_iter=10;, score=0.338 total time= 3.3min\n",
      "Iteration 1, loss = 89565841996.40547180\n",
      "Iteration 2, loss = 66760448560.47205353\n",
      "Iteration 3, loss = 61421580644.89160156\n",
      "Iteration 4, loss = 56915835106.87313080\n",
      "Iteration 5, loss = 54540059030.42611694\n",
      "Iteration 6, loss = 53123790982.31690216\n",
      "Iteration 7, loss = 52111782577.83787537\n",
      "Iteration 8, loss = 51306575083.45102692\n",
      "Iteration 9, loss = 50616694805.40952301\n",
      "Iteration 10, loss = 50023428150.77447510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END hidden_layer_sizes=(16, 4), max_iter=10;, score=0.236 total time= 6.2min\n",
      "Iteration 1, loss = 98039038614.86181641\n",
      "Iteration 2, loss = 75640122603.46699524\n",
      "Iteration 3, loss = 70939471472.11451721\n",
      "Iteration 4, loss = 66139741524.91505432\n",
      "Iteration 5, loss = 63347772647.24191284\n",
      "Iteration 6, loss = 61453023557.42084503\n",
      "Iteration 7, loss = 59956842351.54866791\n",
      "Iteration 8, loss = 58685760496.39670563\n",
      "Iteration 9, loss = 57542547167.09015656\n",
      "Iteration 10, loss = 56545824028.95244598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END hidden_layer_sizes=(16, 4), max_iter=10;, score=0.381 total time= 8.3min\n",
      "Iteration 1, loss = 96627216984.85125732\n",
      "Iteration 2, loss = 74072354236.07437134\n",
      "Iteration 3, loss = 69355338820.26487732\n",
      "Iteration 4, loss = 64566336243.85940552\n",
      "Iteration 5, loss = 61675741623.24427795\n",
      "Iteration 6, loss = 59744069094.01660156\n",
      "Iteration 7, loss = 58251692828.15032959\n",
      "Iteration 8, loss = 56949693531.68425751\n",
      "Iteration 9, loss = 55806918695.91770172\n",
      "Iteration 10, loss = 54793049970.46424866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END hidden_layer_sizes=(16, 4), max_iter=10;, score=0.352 total time= 8.9min\n",
      "Iteration 1, loss = 94999581493.46548462\n",
      "Iteration 2, loss = 72233693191.96241760\n",
      "Iteration 3, loss = 66966556841.18807983\n",
      "Iteration 4, loss = 62301910656.25228119\n",
      "Iteration 5, loss = 59849715573.36222076\n",
      "Iteration 6, loss = 58390533864.74530029\n",
      "Iteration 7, loss = 57358555219.80556488\n",
      "Iteration 8, loss = 56536572455.99349976\n",
      "Iteration 9, loss = 55838890733.20046997\n",
      "Iteration 10, loss = 55237197851.50032043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END hidden_layer_sizes=(16, 4), max_iter=10;, score=0.303 total time= 8.1min\n",
      "Iteration 1, loss = 100428753726.66613770\n",
      "Iteration 2, loss = 76061905839.78451538\n",
      "Iteration 3, loss = 71806184634.91215515\n",
      "Iteration 4, loss = 67172246965.26683807\n",
      "Iteration 5, loss = 63861274387.23213196\n",
      "Iteration 6, loss = 61892991455.87061310\n",
      "Iteration 7, loss = 60410152855.67568207\n",
      "Iteration 8, loss = 59171409364.49687195\n",
      "Iteration 9, loss = 58080530253.21395111\n",
      "Iteration 10, loss = 57095185745.59258270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END hidden_layer_sizes=(16, 4), max_iter=10;, score=0.354 total time= 8.5min\n",
      "Iteration 1, loss = 91237902208.67666626\n",
      "Iteration 2, loss = 71149984305.91304016\n",
      "Iteration 3, loss = 65090701497.04032898\n",
      "Iteration 4, loss = 60993124706.30133057\n",
      "Iteration 5, loss = 58670734145.44852448\n",
      "Iteration 6, loss = 56887276129.87571716\n",
      "Iteration 7, loss = 55397542715.28436279\n",
      "Iteration 8, loss = 54123282988.17343903\n",
      "Iteration 9, loss = 53003795017.81695557\n",
      "Iteration 10, loss = 52040105936.75706482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Workspaces/hudsonmendes-estudos/cm3005-dsc/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (16, 4), 'max_iter': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X1, y1)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(\n",
    "    hidden_layer_sizes=grid.best_params_[\"hidden_layer_sizes\"],\n",
    "    max_iter=200,\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X1, y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X2, y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing remarks/statements\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ff2a5bf76a5a6a6e16a446abb6a1160221241a1606404c7f1c7e55bf8cf0847f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
