{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework Assignment: Building a Regression Model\n",
    "\n",
    "```\n",
    "University of London\n",
    "BSc in Computer Science\n",
    "CM3005, Data Science\n",
    "Hudson Leonardo MENDES\n",
    "hlm12@student.london.ac.uk\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-specific area\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Implementation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_folderpath = pathlib.Path(\"./data\")\n",
    "\n",
    "ppd_folderpath = data_folderpath / \"uk-ppd\"\n",
    "inflation_filepath = data_folderpath / \"uk-ons/ons-inflation-1989-2022.csv\"\n",
    "interest_filepath = data_folderpath / \"uk-boe/boe-interest-1975-2022.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gov.uk/guidance/about-the-price-paid-data\n",
    "ppd_property_type = {\n",
    "    \"D\": \"detached\",\n",
    "    \"S\": \"semi-detached\",\n",
    "    \"T\": \"terraced\",\n",
    "    \"F\": \"flat/maisonettes\",\n",
    "    # \"O\": \"other\" # => intentionally ommitted\n",
    "}\n",
    "\n",
    "ppd_duration = {\"F\": \"freehold\", \"L\": \"leasehold\"}\n",
    "\n",
    "ppd_old_or_new = {\"Y\": \"new\", \"N\": \"old\"}\n",
    "\n",
    "ppd_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\n",
    "            ppd_filepath,\n",
    "            compression=\"zip\",\n",
    "            names=[\n",
    "                \"id\",\n",
    "                \"price\",\n",
    "                \"date\",\n",
    "                \"postcode\",\n",
    "                \"property_type\",\n",
    "                \"old_or_new\",\n",
    "                \"duration\",\n",
    "                \"paon\",\n",
    "                \"saon\",\n",
    "                \"street\",\n",
    "                \"locality\",\n",
    "                \"town_city\",\n",
    "                \"district\",\n",
    "                \"county\",\n",
    "                \"ppd_category_type\",\n",
    "                \"record_status\",\n",
    "            ],\n",
    "        )\n",
    "        for ppd_filepath in ppd_folderpath.glob(\"*.zip\")\n",
    "    ]\n",
    ")\n",
    "ppd_df[\"postgroup\"] = ppd_df[\"postcode\"].map(lambda x: str(x).split(\" \")[0])\n",
    "ppd_df[\"date\"] = pd.to_datetime(ppd_df[\"date\"])\n",
    "ppd_df[\"property_type\"] = ppd_df[\"property_type\"].map(ppd_property_type.get)\n",
    "ppd_df[\"duration\"] = ppd_df[\"duration\"].map(ppd_duration.get)\n",
    "ppd_df[\"old_or_new\"] = ppd_df[\"old_or_new\"].map(ppd_old_or_new.get)\n",
    "ppd_df = ppd_df[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"postgroup\",\n",
    "        \"property_type\",\n",
    "        \"old_or_new\",\n",
    "        \"duration\",\n",
    "        \"price\",\n",
    "    ]\n",
    "]\n",
    "ppd_df = ppd_df.astype(\n",
    "    {\n",
    "        \"postgroup\": \"category\",\n",
    "        \"property_type\": \"category\",\n",
    "        \"old_or_new\": \"category\",\n",
    "        \"duration\": \"category\",\n",
    "        \"price\": \"double\",\n",
    "    }\n",
    ")\n",
    "ppd_df = ppd_df.dropna()\n",
    "ppd_df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from datetime import date\n",
    "\n",
    "inflation_date_pattern = re.compile(r\"([\\d]{4})(?:\\s+([\\w]{3}))?\")\n",
    "inflation_month_names = [\n",
    "    \"JAN\",\n",
    "    \"FEB\",\n",
    "    \"MAR\",\n",
    "    \"APR\",\n",
    "    \"MAY\",\n",
    "    \"JUN\",\n",
    "    \"JUL\",\n",
    "    \"AUG\",\n",
    "    \"SEP\",\n",
    "    \"OCT\",\n",
    "    \"NOV\",\n",
    "    \"DEC\",\n",
    "]\n",
    "inflation_month_index = {mn: ix + 1 for (ix, mn) in enumerate(inflation_month_names)}\n",
    "inflation_month_index[\"Q1\"] = 1\n",
    "inflation_month_index[\"Q2\"] = 4\n",
    "inflation_month_index[\"Q3\"] = 7\n",
    "inflation_month_index[\"Q3\"] = 10\n",
    "\n",
    "inflation_acceptable_numeric_chars = string.digits + \".,\"\n",
    "\n",
    "\n",
    "def extract_inflation_date(x: str) -> date:\n",
    "    match = next(inflation_date_pattern.finditer(x), None)\n",
    "    if match:\n",
    "        group_count = len(match.groups())\n",
    "        if group_count >= 1:\n",
    "            year = int(match.group(1))\n",
    "            month = 1\n",
    "            month_name = match.group(2)\n",
    "            if group_count > 1 and month_name:\n",
    "                month_name = month_name.strip().upper()\n",
    "                month = inflation_month_index.get(month_name)\n",
    "            return date(year, month, 1)\n",
    "\n",
    "\n",
    "def extract_inflation_rate(x: str) -> float:\n",
    "    x = str(x)\n",
    "    if all([c in inflation_acceptable_numeric_chars for c in x]):\n",
    "        return float(x)\n",
    "    return None\n",
    "\n",
    "\n",
    "inflation_df = pd.read_csv(inflation_filepath)\n",
    "inflation_df[\"date\"] = inflation_df[\"Title\"].map(extract_inflation_date)\n",
    "inflation_df[\"date\"] = pd.to_datetime(inflation_df[\"date\"])\n",
    "inflation_df[\"rate\"] = inflation_df[\"CPIH ANNUAL RATE 00: ALL ITEMS 2015=100\"].map(extract_inflation_rate)\n",
    "inflation_df[\"rate\"] = inflation_df[\"rate\"].astype(\"float\", errors=\"ignore\")\n",
    "inflation_df = inflation_df[[\"date\", \"rate\"]]\n",
    "inflation_df = inflation_df.dropna()\n",
    "inflation_df = inflation_df.set_index(\"date\").sort_index()\n",
    "inflation_df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_df = pd.read_csv(interest_filepath)\n",
    "interest_df[\"date\"] = pd.to_datetime(interest_df[\"Date Changed\"])\n",
    "interest_df[\"rate\"] = interest_df[\"Rate\"].astype(\"float\")\n",
    "interest_df = interest_df[[\"date\", \"rate\"]]\n",
    "interest_df = interest_df.set_index(\"date\").sort_index()\n",
    "interest_df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from typing import Callable\n",
    "from datetime import date, timedelta\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def build_rate_extractor(df: pd.DataFrame) -> Callable[[date], float]:\n",
    "    min_date = df.index.min()\n",
    "    max_date = df.index.max()\n",
    "    cur_date = min_date\n",
    "    rate_index = {}\n",
    "    first_rate = df.rate[0]\n",
    "    prev_rate = first_rate\n",
    "    last_rate = df.rate[-1]\n",
    "    with trange((max_date - min_date).days, desc=\"rate_index\") as pbar:\n",
    "        while cur_date <= max_date:\n",
    "            rates = df[df.index == cur_date].rate\n",
    "            if rates.any():\n",
    "                new_rate = rates[0] / 100.0\n",
    "                rate_index[cur_date] = new_rate\n",
    "                prev_rate = new_rate\n",
    "            else:\n",
    "                rate_index[cur_date] = prev_rate\n",
    "            cur_date += timedelta(days=1)\n",
    "            pbar.update()\n",
    "\n",
    "    def get_rate_for_date(d: date) -> float:\n",
    "        if d < min_date:\n",
    "            return first_rate\n",
    "        elif d > max_date:\n",
    "            return last_rate\n",
    "        else:\n",
    "            return rate_index[d]\n",
    "\n",
    "    return get_rate_for_date\n",
    "\n",
    "\n",
    "df = ppd_df.copy()\n",
    "df[\"inflation_rate\"] = df.date.progress_map(build_rate_extractor(df=inflation_df))\n",
    "df[\"interest_rate\"] = df.date.progress_map(build_rate_extractor(df=interest_df))\n",
    "df[\"date_year\"] = df.date.progress_map(lambda d: d.year)\n",
    "df[\"date_month\"] = df.date.progress_map(lambda d: d.month)\n",
    "df[\"date_day\"] = df.date.progress_map(lambda d: d.day)\n",
    "df[\"date_day_of_week\"] = df.date.progress_map(lambda d: d.weekday())\n",
    "df = df.sort_values(by=\"date\").reset_index()\n",
    "df = df[\n",
    "    [\"date_year\", \"date_month\", \"date_day\", \"date_day_of_week\"]\n",
    "    + list(ppd_df.columns[1:-1])\n",
    "    + [\"inflation_rate\", \"interest_rate\", \"price\"]\n",
    "]\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_folderpath / \"snapshot-Xy-1NF.zip\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert df is not None\n",
    "except NameError:\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"[SNAPSHOT] Reloading...\")\n",
    "    pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n",
    "    data_folderpath = pathlib.Path(\"./data\")\n",
    "    df = pd.read_csv(data_folderpath / \"snapshot-Xy-1NF.zip\").astype(\n",
    "        {\n",
    "            \"postgroup\": \"category\",\n",
    "            \"property_type\": \"category\",\n",
    "            \"old_or_new\": \"category\",\n",
    "            \"duration\": \"category\",\n",
    "            \"price\": \"double\",\n",
    "        }\n",
    "    )\n",
    "    print(f\" - reloaded from snapshot, {df.shape[0]}\")\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_continuous = df.select_dtypes(include=\"float\")\n",
    "df_feats_continuous.sample(n=5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Tendency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_central_tendency = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(df_feats_continuous.mean(), columns=[\"mean\"]).transpose(),\n",
    "        pd.DataFrame(df_feats_continuous.median(), columns=[\"median\"]).transpose(),\n",
    "        pd.DataFrame([df_feats_continuous[c].mode()[0] for c in df_feats_continuous.columns], columns=[\"mode\"])\n",
    "        .set_index(df_feats_continuous.columns)\n",
    "        .transpose(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_central_tendency\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Spread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measures_of_spread = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(df_feats_continuous.var(), columns=[\"var\"]).transpose(),\n",
    "        df_feats_continuous.describe(),\n",
    "        pd.DataFrame(\n",
    "            df_feats_continuous.quantile(0.75) - df_feats_continuous.quantile(0.25), columns=[\"IQR\"]\n",
    "        ).transpose(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "df_measures_of_spread\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_types_of_distros = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(df_feats_continuous.skew(), columns=[\"skew\"]).transpose(),\n",
    "        pd.DataFrame(df_feats_continuous.kurtosis(), columns=[\"kurtosis\"]).transpose(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_types_of_distros\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SNAPSHOT] Reloading...\n",
      " - reloaded from snapshot, 4336841\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert df is not None\n",
    "except NameError:\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "\n",
    "    print(\"[SNAPSHOT] Reloading...\")\n",
    "    pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n",
    "    data_folderpath = pathlib.Path(\"./data\")\n",
    "    df = pd.read_csv(data_folderpath / \"snapshot-Xy-1NF.zip\").astype(\n",
    "        {\n",
    "            \"postgroup\": \"category\",\n",
    "            \"property_type\": \"category\",\n",
    "            \"old_or_new\": \"category\",\n",
    "            \"duration\": \"category\",\n",
    "            \"price\": \"double\",\n",
    "        }\n",
    "    )\n",
    "    print(f\" - reloaded from snapshot, {df.shape[0]}\")\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_continuous = df.select_dtypes(include=\"float\")\n",
    "df_feats_continuous.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Continuous Attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "df_feats_scaled_continuous_with_ptype = df[list(df_feats_continuous.columns) + [\"property_type\"]]\n",
    "sns.pairplot(\n",
    "    data=df_feats_scaled_continuous_with_ptype.sample(n=int(df_feats_scaled_continuous_with_ptype.shape[0] * 0.01)),\n",
    "    hue=\"property_type\",\n",
    "    kind=\"scatter\",\n",
    "    diag_kind=\"kde\",\n",
    "    palette=\"viridis\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions for Inflation Rate & Interest Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rate_distributions(ax, df: pd.DataFrame, label: str, color: str):\n",
    "    df = df.copy()\n",
    "    df[\"rate\"] = df[\"rate\"] * 100.0\n",
    "    x = np.linspace(0.0, df[\"rate\"].max(), 100)\n",
    "    df[\"bin\"] = pd.cut(df[\"rate\"], bins=x)\n",
    "    y = list(df.groupby(\"bin\").count()[\"rate\"])\n",
    "    ax.fill_between(x[:-1], 0.0, y, color=color, alpha=0.5)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter(\"%2.2f%%\"))\n",
    "    intervals = [0.05, 0.5, 0.95]\n",
    "    for interval, quantile in zip(intervals, df.rate.quantile(intervals)):\n",
    "        percentile = f\"P{int(interval*100.)}={round(quantile, 2)}\"\n",
    "        bbox = dict(boxstyle=\"round, pad=0.3\", fc=\"lightgray\", lw=2)\n",
    "        ax.axvline(x=quantile, color=\"blue\")\n",
    "        ax.annotate(\n",
    "            percentile,\n",
    "            xy=(quantile, max(y)),\n",
    "            bbox=bbox,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    ax.axvline(x=quantile, color=\"blue\")\n",
    "    ax.legend([label], loc=\"lower center\", bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "\n",
    "df_daily_means = df.groupby([\"date_year\", \"date_month\", \"date_day\"]).mean(numeric_only=True)\n",
    "df_daily_means_interest = df_daily_means[[\"interest_rate\"]].rename(columns={\"interest_rate\": \"rate\"})\n",
    "df_daily_means_inflation = df_daily_means[[\"inflation_rate\"]].rename(columns={\"inflation_rate\": \"rate\"})\n",
    "_, axes = plt.subplots(ncols=2, nrows=1, figsize=(15, 5))\n",
    "plot_rate_distributions(\n",
    "    ax=axes[0],\n",
    "    df=df_daily_means_interest,\n",
    "    label=\"interest\",\n",
    "    color=\"green\",\n",
    ")\n",
    "plot_rate_distributions(\n",
    "    ax=axes[1],\n",
    "    df=df_daily_means_inflation,\n",
    "    label=\"inflation\",\n",
    "    color=\"red\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Distribution Inflation, Interest & Property Price per Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "def plot_inflation_and_interest(\n",
    "    ax: plt.Axes,\n",
    "    df_mean_by_date: pd.DataFrame,\n",
    "    xlim_left: float,\n",
    "    xlim_right: float,\n",
    "):\n",
    "    df_mean_by_date = df_mean_by_date.reset_index()\n",
    "    x = df_mean_by_date.apply(lambda r: date(int(r.date_year), int(r.date_month), int(r.date_day)), axis=1)\n",
    "    ax.grid(visible=True)\n",
    "    ax.plot(x, df_mean_by_date.interest_rate * 100.0, \"g.-\", alpha=0.7)\n",
    "    ax.plot(x, df_mean_by_date.inflation_rate * 100.0, \"r.-\", alpha=0.7)\n",
    "    ax.set_xlim(left=xlim_left, right=xlim_right)\n",
    "    ax.set_ylabel(\"rates (%)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%2.2f%%\"))\n",
    "    ax.legend([\"interest\", \"inflation\"])\n",
    "\n",
    "\n",
    "def plot_prices_per_property_type(\n",
    "    ax: plt.Axes,\n",
    "    df_mean_by_date_and_pt: pd.DataFrame,\n",
    "):\n",
    "    df_mean_by_date_and_pt = df_mean_by_date_and_pt.reset_index()\n",
    "    ax.grid(visible=True)\n",
    "    ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:,}\"))\n",
    "    ax.set_ylim(0.0, df_mean_by_date_and_pt.price.quantile(0.95) * 1.2)\n",
    "    ax.set_ylabel(\"property price (£)\")\n",
    "    property_types = sorted(df_mean_by_date_and_pt.property_type.unique())\n",
    "    for ix, property_type in tqdm(list(enumerate(property_types))):\n",
    "        sub_series = df_mean_by_date_and_pt[df_mean_by_date_and_pt.property_type == property_type].copy()\n",
    "        sub_series = sub_series.reset_index().groupby([\"date_year\", \"date_month\"]).mean(numeric_only=True).reset_index()\n",
    "        sub_series = sub_series.fillna(method=\"ffill\")\n",
    "        x = sub_series.apply(lambda r: date(int(r.date_year), int(r.date_month), 1), axis=1)\n",
    "        ax.plot(x, sub_series.price, \"s\", alpha=0.7)\n",
    "        ax.legend(property_types)\n",
    "\n",
    "\n",
    "min_intersecting_date = date(df.date_year.min(), 1, 1)\n",
    "max_intersecting_date = date(df.date_year.max(), 12, 30)\n",
    "_, axes = plt.subplots(nrows=2, figsize=(15, 10), sharex=True)\n",
    "plot_inflation_and_interest(\n",
    "    ax=axes[0],\n",
    "    df_mean_by_date=df.groupby([\"date_year\", \"date_month\", \"date_day\"]).mean(numeric_only=True),\n",
    "    xlim_left=min_intersecting_date,\n",
    "    xlim_right=max_intersecting_date,\n",
    ")\n",
    "plot_prices_per_property_type(\n",
    "    ax=axes[1],\n",
    "    df_mean_by_date_and_pt=df.groupby([\"date_year\", \"date_month\", \"date_day\", \"property_type\"]).mean(numeric_only=True),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert df is not None\n",
    "except NameError:\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"[SNAPSHOT] Reloading...\")\n",
    "    pd.set_option(\"display.float_format\", lambda x: \"{:,.3f}\".format(x))\n",
    "    data_folderpath = pathlib.Path(\"./data\")\n",
    "    df = pd.read_csv(data_folderpath / \"snapshot-Xy-1NF.zip\").astype(\n",
    "        {\n",
    "            \"postgroup\": \"category\",\n",
    "            \"property_type\": \"category\",\n",
    "            \"old_or_new\": \"category\",\n",
    "            \"duration\": \"category\",\n",
    "            \"price\": \"double\",\n",
    "        }\n",
    "    )\n",
    "    print(f\" - reloaded from snapshot, {df.shape[0]}\")\n",
    "df.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[df.columns[:-1]], df[df.columns[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "\n",
    "def make_sine_cycle_encoder(period: int = 1) -> float:\n",
    "    assert period != 0\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use\n",
    "def make_df_column_transformer():\n",
    "    categorical_selector = make_column_selector(dtype_include=\"category\")\n",
    "    float_seletor = make_column_selector(dtype_include=\"float64\")\n",
    "    one_hot = OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\")\n",
    "    numerical_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    cycle_sine_12 = make_sine_cycle_encoder(period=12)\n",
    "    cycle_sine_31 = make_sine_cycle_encoder(period=31)\n",
    "    cycle_sine_6 = make_sine_cycle_encoder(period=6)\n",
    "    return make_column_transformer(\n",
    "        (one_hot, categorical_selector),\n",
    "        (numerical_scaler, float_seletor),\n",
    "        (numerical_scaler, [\"date_year\"]),\n",
    "        (cycle_sine_12, [\"date_month\"]),\n",
    "        (cycle_sine_31, [\"date_day\"]),\n",
    "        (cycle_sine_6, [\"date_day_of_week\"]),\n",
    "        remainder=\"drop\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "preprocessing_df_column_transformer = make_df_column_transformer()\n",
    "X_encoded = preprocessing_df_column_transformer.fit_transform(X)\n",
    "pd.DataFrame.sparse.from_spmatrix(X_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def produce_split_summary(\n",
    "    X_split: pd.DataFrame, y_split: pd.DataFrame, name: str, total: int\n",
    ") -> Tuple[str, int, int, str]:\n",
    "    return (\n",
    "        name,\n",
    "        X_split.shape[0],\n",
    "        y_split.shape[0],\n",
    "        \"{:.1f}%\".format(100.0 * X_split.shape[0] / total),\n",
    "    )\n",
    "\n",
    "\n",
    "r = 42\n",
    "train_size = 0.99\n",
    "X1, X2, y1, y2 = train_test_split(X_encoded, y, train_size=train_size, random_state=r)\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        produce_split_summary(X, y, \"full\", total=X.shape[0]),\n",
    "        produce_split_summary(X1, y1, \"train\", total=X.shape[0]),\n",
    "        produce_split_summary(X2, y2, \"test\", total=X.shape[0]),\n",
    "    ],\n",
    "    columns=[\"split\", \"|X|\", \"|y|\", \"%\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "def make_model(hidden_layer_sizes: Tuple[int, ...], max_iter: int):\n",
    "    r = 42\n",
    "    return MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        validation_fraction=0.01,\n",
    "        random_state=r,\n",
    "        verbose=True,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "\n",
    "\n",
    "model = make_model(hidden_layer_sizes=(2,), max_iter=1)\n",
    "model.fit(X1, y1)\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        (\"train\", model.score(X1, y1)),\n",
    "        (\"test\", model.score(X2, y2)),\n",
    "    ],\n",
    "    columns=[\"spit\", \"score\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Set, List, Tuple\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (2, 4),\n",
    "            (3, 4),\n",
    "            (4, 4),\n",
    "            (8, 4),\n",
    "            (16, 4),\n",
    "        ],\n",
    "        \"max_iter\": [10],\n",
    "    },\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    ")\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X1, y1)\n",
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(\n",
    "    hidden_layer_sizes=grid.best_params_[\"hidden_layer_sizes\"],\n",
    "    max_iter=200,\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X1, y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X2, y2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Conclusions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing remarks/statements\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff2a5bf76a5a6a6e16a446abb6a1160221241a1606404c7f1c7e55bf8cf0847f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
